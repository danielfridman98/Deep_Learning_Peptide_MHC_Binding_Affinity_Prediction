# -*- coding: utf-8 -*-
"""sequence_embedding_tensors

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H3R-0UDPP5MuBAwO6ZesGuYxCGfd_y0S
"""

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir('/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master')

!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html

import torch
import torch.nn as nn 
import torch.nn.functional as F
import pandas as pd
import numpy as np
from peptide_embedding import *  
from MHC_sequence_embedding import *
from random import sample

# Full Model w/MHC embedding
# Full Model w/MHC embedding

pretrained_model = torch.load('ssa_L1_100d_lstm3x512_lm_i512_mb64_tau0.5_lambda0.1_p0.05_epoch100.sav')


# Load Dataset 
# Dataset of peptide sequence, MHC allele name, binary binding affinity (positive, negative)
link1 = 'https://raw.githubusercontent.com/cmb-chula/MHCSeqNet/master/cleaned_MHC_all_classes.csv'
x = pd.read_csv(link1)

# Dataset of corresponding amino acid sequence for MHC alleles (Beta sheet, alpha helix res 140-179, alpha helix res 50-84)
link2 = 'https://raw.githubusercontent.com/cmb-chula/MHCSeqNet/master/PretrainedModels/sequence_model/AlleleInformation.txt'
allele_seq = urllib.request.urlopen(link2)
MHC_sequence_df = MHC_seq_df(allele_seq)

# Process and randomize data
alleles = x['allele']
good_idx = alleles.isin(MHC_sequence_df['MHC_allele'])
classI_alleles = alleles[good_idx]

# classI_idx = classI_alleles.axes[0].to_list()
# rand_idx = np.random.permutation(classI_idx)
# classI_alleles = classI_alleles[rand_idx]

# alpha_res_140_179, alpha_res_50_84 = allele_sequence(classI_alleles, MHC_sequence_df)
alpha_res_140_179_read = pd.read_csv("allele_sequences/140_179.csv")
alpha_res_50_84_read = pd.read_csv("allele_sequences/50_84.csv")

# SHOULD UNCOMMENT THIS CODE TO STRIP \N FROM AMINO ACID SEQUENCE
# alpha_res_50_84_read.iloc[:,0] = alpha_res_50_84_read.iloc[:,0].map(lambda x: x.rstrip('\n'))
# alpha_res_140_179_read.iloc[:,0] = alpha_res_140_179_read.iloc[:,0].map(lambda x: x.rstrip('\n'))

alpha_res_140_179_encoding = peptide_encoding(alpha_res_140_179_read.squeeze())
alpha_res_50_84_encoding = peptide_encoding(alpha_res_50_84_read.squeeze())

# alpha_res_140_179.to_csv("/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/140_179.csv",index = False)
# alpha_res_50_84.to_csv("/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/50_84.csv",index = False)

peptides = x['peptide'] 
peptides = peptides[good_idx]
# peptides = peptides[rand_idx]
peptide_encode = peptide_encoding(peptides)

#peptide_embedding(peptide_encoding, 15, pretrained_model)
peptide_embedding_list = []
tensor_idx = 0
for i in range(0,len(peptide_encode),1000):
  print(i)
  peptide_embeddings = peptide_embedding(peptide_encode[i:i+1000], 15, pretrained_model)
  peptide_embeddings = torch.stack(peptide_embeddings)
  peptide_embedding_list.append(peptide_embeddings)
  if i % 10000 == 0:
    peptide_tensor = torch.cat(peptide_embedding_list, dim=0)
    path = '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/' + 'peptide_tensor' + str(tensor_idx)
    torch.save(peptide_tensor, path)
    tensor_idx += 1
    peptide_embedding_list = []

# binding_affinity = x['binding_quality']
# binding_affinity = binding_affinity[good_idx]
# binding_affinity = binding_affinity[rand_idx]
# binding_affinity = binding_affinity.values.tolist()
    
# y = np.array(binding_affinity_class(binding_affinity))

#peptide_embedding(peptide_encoding, 15, pretrained_model)
alpha_140_179_list = []
tensor_idx = 0
for i in range(0,len(alpha_res_140_179_encoding),1000):
  print(i)
  allele_140_179_embeddings = peptide_embedding(alpha_res_140_179_encoding[i:i+1000], 53, pretrained_model)
  allele_140_179_embeddings = torch.stack(allele_140_179_embeddings)
  alpha_140_179_list.append(allele_140_179_embeddings)
  if i % 1000 == 0:
    alpha_140_179_tensor = torch.cat(alpha_140_179_list, dim=0)
    path = '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/' + 'alpha_res_140_179_tensor' + str(tensor_idx)
    torch.save(alpha_140_179_tensor, path)
    tensor_idx += 1
    alpha_140_179_list = []

#peptide_embedding(peptide_encoding, 15, pretrained_model)
embedding_50_84_list = []
tensor_idx = 0
for i in range(0,len(alpha_res_50_84_encoding),1000):
  print(i)
  embedding_50_84 = peptide_embedding(alpha_res_50_84_encoding[i:i+1000], 53, pretrained_model)
  embedding_50_84 = torch.stack(embedding_50_84)
  embedding_50_84_list.append(embedding_50_84)
  if i % 1000 == 0:
    embedding_50_84_tensor = torch.cat(embedding_50_84_list, dim=0)
    path = '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/' + 'embedding_50_84_tensor' + str(tensor_idx)
    torch.save(embedding_50_84_tensor, path)
    tensor_idx += 1
    embedding_50_84_list = []

tensor_list = []
for i in range(23):
  file_name = 'peptide_tensor' + str(i)
  tensor = torch.load(file_name)
  tensor_list.append(tensor)

peptide_tensor = torch.cat(tensor_list, dim=0)

peptide_tensor.shape

peptide_embedding_list = []
tensor_idx = 0
for i in range(221000,len(peptide_encode),1000):
  print(i)
  peptide_embeddings = peptide_embedding(peptide_encode[i:i+1000], 15, pretrained_model)
  peptide_embeddings = torch.stack(peptide_embeddings)
  peptide_embedding_list.append(peptide_embeddings)

last_peptide_tensor = torch.cat(peptide_embedding_list, dim=0)
path = '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/' + 'peptide_tensor23'
torch.save(last_peptide_tensor, path)

last_tensor = torch.load('peptide_tensor23')

peptide_tensor = torch.cat((peptide_tensor, last_tensor), dim=0)

peptide_tensor.shape

torch.save(peptide_tensor, '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/data_tensors/peptide_tensor_full_data')





tensor_list = []
for i in range(230):
  print(i)
  file_name = 'alpha_res_140_179_tensor' + str(i)
  tensor = torch.load(file_name)
  tensor_list.append(tensor)

alpha_140_179_tensor = torch.cat(tensor_list, dim=0)

alpha_140_179_tensor.shape

torch.save(alpha_140_179_tensor, '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/data_tensors/alpha_140_179_full_data')



tensor_list = []
for i in range(230):
  print(i)
  file_name = 'embedding_50_84_tensor' + str(i)
  tensor = torch.load(file_name)
  tensor_list.append(tensor)

alpha_50_84_tensor = torch.cat(tensor_list, dim=0)

alpha_50_84_tensor.shape

torch.save(alpha_50_84_tensor, '/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/data_tensors/alpha_50_84_full_data')















