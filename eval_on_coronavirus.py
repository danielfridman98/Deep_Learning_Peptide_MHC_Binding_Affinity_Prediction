"""eval_on_coronavirus.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1VwdQXpLY9Qi74QrEveqeEaphPtcfHsct
"""

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir('/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master')
# Installs Pytorch 1.2 (later versions don't work)
# get_ipython().system('pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html')
!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html


import torch
import torch.nn as nn 
import torch.nn.functional as F
import pandas as pd
import numpy as np


print(torch.__version__)
# From Peptide_MHC_all_sequence_model.ipynb
class peptide_BiGRU(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(peptide_BiGRU, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size

        self.peptide_bidir_gru =  nn.GRU(input_size, hidden_size, batch_first=True, bidirectional = True)
        
    def forward(self, x):
        gru_output, _ = self.peptide_bidir_gru(x) # gru_output: tensor of shape (batch_size, seq_length, hidden_size*2)
        # gru_output = torch.cat((gru_output[:,0,:], gru_output[:,-1,:]), dim=1) # concatenate hidden layer for first and latest time step
        gru_output = torch.cat((gru_output[:,0,:], gru_output[:,-1,:]), dim=1)
        return gru_output
    
class allele_BiGRU(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(allele_BiGRU, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        
        self.allele_bidir_gru = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)
        
    def forward(self, x): 
        gru_output, _ = self.allele_bidir_gru(x)
        gru_output = torch.cat((gru_output[:,0,:], gru_output[:,-1,:]), dim=1)
        return gru_output 
    
class Output_Layer(nn.Module):
    def __init__(self, peptide_BiGRU_model, allele_BiGRU_model, peptide_dim, allele_dim):
        super(Output_Layer, self).__init__()
        self.peptide_model = peptide_BiGRU_model
        self.allele_model = allele_BiGRU_model
        
        self.Hidden1 = nn.Linear((peptide_dim + allele_dim), 200)
        self.Hidden2 = nn.Linear(200, 200)
        self.output = nn.Linear(200,1)
        self.relu = nn.ReLU()
        
    def forward(self, peptide_input, allele_input):
        peptide_output = self.peptide_model(peptide_input)
        allele_output = self.allele_model(allele_input)
        
        input_concat = torch.cat((peptide_output, allele_output), dim=1)
        Hidden1 = self.relu(self.Hidden1(input_concat))
        Hidden2 = self.relu(self.Hidden2(Hidden1))
        output = torch.sigmoid(self.output(Hidden2))
        return output

# Loads Coronavirus Peptide Sequences
# Full data has too many peptides of length 11-15
# corona_embedding_tensor = torch.load('corona_peptides/all_corona_embeddings.pt').cuda()
# corona_peptides = pd.read_csv('corona_peptides/all_coronavirus_peptides.txt', header=None)
corona_embedding_tensor = torch.load('corona_peptides/subset_corona_embeddings.pt').cuda()
print(corona_embedding_tensor.shape)
corona_peptides = pd.read_csv("corona_peptides/subset_corona_peptides.txt", header=None)
corona_peptides.columns = ['peptide']

# Loads MHC Allele Sequences
alpha_140_179_embedding_tensor = torch.load('data_tensors/common_140_179_embeddings.pt')
alpha_50_84_embedding_tensor = torch.load('data_tensors/common_50_84_embeddings.pt')
allele_embedding_tensor = torch.cat((alpha_140_179_embedding_tensor, alpha_50_84_embedding_tensor), dim=1).cuda()
print(allele_embedding_tensor.shape)
alleles = pd.read_csv("allele_sequences/30_mhc_alleles.csv")

# Defines model
peptide_embedding_dim = 100
peptide_hidden_dim = 100

allele_embedding_dim = 100
allele_hidden_dim = 100

peptide_to_output_dim = peptide_hidden_dim*2*2
allele_to_output_dim = allele_hidden_dim*2*2

peptide_model = peptide_BiGRU(peptide_embedding_dim, peptide_hidden_dim).cuda()
allele_model = allele_BiGRU(allele_embedding_dim, allele_hidden_dim).cuda()
output_model = Output_Layer(peptide_model, allele_model, peptide_to_output_dim, allele_to_output_dim).cuda()
output_model.load_state_dict(torch.load('/content/drive/My Drive/Deep_Learning_Final_Project/protein-sequence-embedding-iclr2019-master/trained_peptide_allele_sequence_full_model.pt'))

affinities = []
for i in range(corona_peptides.shape[0]):
  peptide_affinities = []
  for j in range(alleles.shape[0]):
    peptide = torch.reshape(corona_embedding_tensor[i, :, :], (1, 15, 100))
    allele = torch.reshape(allele_embedding_tensor[j, :, :], (1, 106, 100))
    binding_pred = output_model(peptide, allele).item()
    peptide_affinities.append(binding_pred)
  affinities.append(peptide_affinities)
  if i % 100 == 0:
    print(i)

n_alleles = 30
all_affs = []
HLA_A_affs = []
HLA_B_affs = []
HLA_C_affs = []
[all_affs.extend(el) for el in affinities]
[HLA_A_affs.extend(el[:10]) for el in affinities]
[HLA_B_affs.extend(el[10:20]) for el in affinities]
[HLA_C_affs.extend(el[20:]) for el in affinities]

avg_aff = sum(all_affs) / len(all_affs)
meanHLA_A = sum(HLA_A_affs) / len(HLA_A_affs)
meanHLA_B = sum(HLA_B_affs) / len(HLA_B_affs)
meanHLA_C = sum(HLA_C_affs) / len(HLA_C_affs)

print("Mean Binding Affinity between peptides and 30 MHC-I alleles:", round(avg_aff, 3))
print("Mean Binding Affinity between peptides and 10 MHC-I alleles with gene:")
print("- HLA-A: {}".format(round(meanHLA_A, 3)))
print("- HLA-B: {}".format(round(meanHLA_B, 3)))
print("- HLA-C: {}\n".format(round(meanHLA_C, 3)))

# Shows binding affinities by percentile
x = sorted(all_affs)
print("25th percentile:", round(x[int(len(x)*.25)], 3))
print("50th percentile:", round(x[int(len(x)*.5)], 3))
print("75th percentile: %f\n" % round(x[int(len(x)*.75)], 3))

# Almost all peptides will certainly bind to at least 1 MHC allele
n_peptides = len(affinities)
near_one_all = []
near_zero_all = []
either_all = []
for pep_affs in affinities:
  near_one = []
  near_zero = []
  either = []
  for aff in pep_affs:
    near_one.append(aff >= 0.9)
    near_zero.append(aff <= 0.1)
    either.append(aff >= 0.9 or aff <= 0.1)
  near_one_all.append(near_one)
  near_zero_all.append(near_zero)
  either_all.append(either)

pct_near_one = sum([sum(near_one) / n_alleles for near_one in near_one_all]) / n_peptides
pct_near_zero = sum([sum(near_zero) / n_alleles for near_zero in near_zero_all]) / n_peptides
pct_either = sum([sum(either) / n_alleles for either in either_all]) / n_peptides
print("Percentage of binding affinities over 0.9: {}%".format(round(pct_near_one*100, 1)))
print("Percentage of binding affinities under 0.1: {}%".format(round(pct_near_zero*100, 1)))
print("Either (under 0.1 or over 0.9): {}%".format(round(pct_either*100, 1)))

pctHLA_A = sum([sum(in_range[:10]) / 10 for in_range in near_one_all]) / n_peptides
pctHLA_B = sum([sum(in_range[10:20]) / 10 for in_range in near_one_all]) / n_peptides
pctHLA_C = sum([sum(in_range[20:]) / 10 for in_range in near_one_all]) / n_peptides
print("Percent over 0.9, by gene:")
print("- HLA-A: {}%".format(round(pctHLA_A*100, 1)))
print("- HLA-B: {}%".format(round(pctHLA_B*100, 1)))
print("- HLA-C: {}%".format(round(pctHLA_C*100, 1)))

# Finds average affinity by protein
# Extracts each protein's amino acid sequence
corona = pd.read_csv("coronavirus_netchop.csv")
aa_indices = corona.index[corona['pos'] == 1].tolist()
n_proteins = len(aa_indices)
protein_list = []
for i in range(n_proteins):
  if i < len(aa_indices) - 1:
    end_index = aa_indices[i + 1]
  else:
    end_index = corona.shape[0]
  protein = "".join(corona['AA'].iloc[aa_indices[i]:end_index].to_list())
  protein_list.append(protein)

# Finds which proteins each peptide is in
protein_affinities = [[] for _ in range(n_proteins)]
for i in range(n_peptides):
  peptide = corona_peptides.peptide.iloc[i]
  for j in range(n_proteins):
    if peptide in protein_list[j]:
      protein_affinities[j].append(affinities[i])

# Calculates average binding affinity per protein
print("Number of proteins:", n_proteins)
for i in range(n_proteins):
  count = len(protein_affinities[i])
  if count == 0: 
    continue
  avg_aff = sum([sum(pep_affs) / len(pep_affs) for pep_affs in protein_affinities[i]]) / count
  print("Mean Binding Affinity between 30 MHC-I alleles and the {} peptides found in protein {}: {}"
        .format(count, i+1, round(avg_aff, 3)))

# Protein 11 is the Spike Protein
count = len(protein_affinities[10])
spike_avg = sum([sum(pep_affs) / len(pep_affs) for pep_affs in protein_affinities[10]]) / count
print("Spike protein (11) mean binding affinity: {}".format(round(spike_avg, 3)))

meanHLA_A = sum([sum(pep_affs[:10]) / 10 for pep_affs in protein_affinities[10]]) / count
meanHLA_B = sum([sum(pep_affs[10:20]) / 10 for pep_affs in protein_affinities[10]]) / count
meanHLA_C = sum([sum(pep_affs[20:]) / 10 for pep_affs in protein_affinities[10]]) / count
print("By gene:")
print("- HLA-A: {}".format(round(meanHLA_A, 3)))
print("- HLA-B: {}".format(round(meanHLA_B, 3)))
print("- HLA-C: {}".format(round(meanHLA_C, 3)))

# Breaks peptides apart by length
length_affinities = [[] for _ in range(8)]
for i in range(n_peptides):
  peptide = corona_peptides.peptide.iloc[i]
  length_affinities[len(peptide)-8].append(affinities[i])

# Calculates mean binding affinity by peptide length
for i in range(8):
  all = []
  [all.extend(peps) for peps in length_affinities[i]]
  avg_aff = sum(all) / len(all)
  print("{} peptides of length {}".format(len(length_affinities[i]), i+8))
  print("- Mean binding affinity:", round(avg_aff, 2))
  sorted_affs = sorted(all)
  count = len(sorted_affs)
  first_idx = [aff >= 0.9 for aff in sorted_affs].index(True)
  pct_over = round((count - first_idx) / count * 100)
  print("- Percentage of binding affinities above 0.9: {}%".format(pct_over))
